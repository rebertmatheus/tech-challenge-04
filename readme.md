# Tech Challenge 04 - Sistema de PrediÃ§Ã£o de AÃ§Ãµes com LSTM

Sistema completo de prediÃ§Ã£o de preÃ§os de aÃ§Ãµes da B3 utilizando redes neurais LSTM (Long Short-Term Memory), implementado na nuvem Azure com arquitetura serverless.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Arquitetura](#arquitetura)
- [Status do Projeto](#status-do-projeto)
- [PrÃ©-requisitos](#prÃ©-requisitos)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [InstalaÃ§Ã£o e Setup](#instalaÃ§Ã£o-e-setup)
- [DocumentaÃ§Ã£o Detalhada](#documentaÃ§Ã£o-detalhada)
- [Roadmap](#roadmap)

---

## ğŸ¯ VisÃ£o Geral

Este projeto implementa um sistema end-to-end para prediÃ§Ã£o de preÃ§os de aÃ§Ãµes utilizando:

- **Coleta AutomÃ¡tica de Dados**: Azure Functions que buscam dados histÃ³ricos e diÃ¡rios via yfinance
- **Feature Engineering**: 23 indicadores tÃ©cnicos otimizados para prediÃ§Ã£o de curto prazo
- **Modelo LSTM**: Rede neural recorrente com PyTorch Lightning para previsÃ£o de preÃ§o ajustado (D+1)
- **Infraestrutura Cloud**: Azure Functions, Storage Account, Cosmos DB, API Management
- **Monitoramento**: Application Insights e dashboards customizados

### Objetivo

Prever o preÃ§o de fechamento ajustado (Adj Close) de aÃ§Ãµes da B3 para o prÃ³ximo dia Ãºtil (D+1) utilizando dados histÃ³ricos e indicadores tÃ©cnicos.

---

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Logic App     â”‚  (Trigger diÃ¡rio)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data-Service   â”‚  (Azure Function)
â”‚  - fetch-historyâ”‚  â†’ /history/{ticker}.parquet
â”‚  - fetch-day    â”‚  â†’ /YYYY/MM/DD/{ticker}.parquet
â”‚  - health       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Storage Account â”‚
â”‚  - /history/    â”‚  (Dados histÃ³ricos completos)
â”‚  - /YYYY/MM/DD/ â”‚  (SÃ©ries de 90 dias)
â”‚  - /models/     â”‚  (Modelos treinados)
â”‚  - /hyperparams/â”‚  (ConfiguraÃ§Ãµes por ticker)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stock-Service  â”‚  (Azure Function) [PENDENTE]
â”‚  - /train       â”‚  â†’ Treina modelo LSTM
â”‚  - /predict     â”‚  â†’ Retorna prediÃ§Ã£o D+1
â”‚  - /health      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cosmos DB     â”‚  [PENDENTE]
â”‚  - model_versionsâ”‚  (VersÃµes de modelos)
â”‚  - metrics      â”‚  (MÃ©tricas de treinamento)
â”‚  - predictions  â”‚  (Cache de prediÃ§Ãµes)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Management â”‚  [PENDENTE]
â”‚  - /data/*      â”‚  (Endpoints do Data-Service)
â”‚  - /stock/*     â”‚  (Endpoints do Stock-Service)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… Status do Projeto

### FASE 1: Data-Service (Azure Function) - âœ… **CONCLUÃDO**

**Status**: Implementado e funcional

- [x] Endpoint `fetch-history` (busca histÃ³rico completo + feature engineering)
- [x] Endpoint `fetch-day` (busca Ãºltimos 90 dias + feature engineering)
- [x] Health check `/health` implementado
- [x] Application Insights habilitado
- [x] Feature Engineering com 23 indicadores tÃ©cnicos
- [x] IntegraÃ§Ã£o com Azure Storage Account
- [x] Suporte a mÃºltiplos tickers configurÃ¡veis

**Outputs**:
- `/history/{ticker}.parquet` - Dados histÃ³ricos completos com features
- `/YYYY/MM/DD/{ticker}.parquet` - SÃ©ries temporais de 90 dias para prediÃ§Ã£o

**Endpoints DisponÃ­veis**:
- `GET /api/fetch-history` - Busca histÃ³rico completo
- `GET /api/fetch-day` - Busca Ãºltimos 90 dias
- `GET /api/health` - Health check

---

### FASE 2: Modelo LSTM (Desenvolvimento Local) - âœ… **CONCLUÃDO**

**Status**: Modelo desenvolvido e testado localmente

#### 2.1 Arquitetura do Modelo âœ…

- [x] Classe `StocksLSTM` usando PyTorch Lightning
- [x] Input: 23 features, SequÃªncia: 70-90 dias (configurÃ¡vel por ticker)
- [x] Output: Adj Close (D+1)
- [x] HiperparÃ¢metros configurÃ¡veis por ticker (JSON)

**Arquitetura**:
```
Input (23 features Ã— 70-90 timesteps) 
  â†’ LSTMâ‚ (200 hidden) 
  â†’ Dropout (0.2) 
  â†’ LSTMâ‚‚ (100 hidden) 
  â†’ Dropout (0.2) 
  â†’ LSTMâ‚ƒ (100 hidden, 2 layers) 
  â†’ Dropout (0.2) 
  â†’ Linear 
  â†’ Output (Adj Close D+1)
```

#### 2.2 Pipeline de Treinamento âœ…

- [x] Carregamento de dados de `/history/{ticker}.parquet`
- [x] Split 75/15/10 (treino/validaÃ§Ã£o/teste)
- [x] NormalizaÃ§Ã£o com MinMaxScaler (0-1)
- [x] DataLoader com sequÃªncias temporais
- [x] Training loop com PyTorch Lightning
- [x] Early stopping e learning rate scheduler
- [x] CÃ¡lculo de mÃ©tricas:
  - MAE (Mean Absolute Error)
  - RMSE (Root Mean Squared Error)
  - MAPE (Mean Absolute Percentage Error)
  - RÂ² (Coeficiente de DeterminaÃ§Ã£o)
  - AcurÃ¡cia direcional

#### 2.3 Testes Locais âœ…

- [x] Treinamento testado com PETR4, ITUB4, VALE3
- [x] ValidaÃ§Ã£o de prediÃ§Ãµes
- [x] Salvamento de modelo + scaler localmente
- [x] Resultados documentados

**Resultados Obtidos (PETR4)**:
- RÂ²: **63.26%**
- MAPE: **1.40%**
- MAE: R$ 0.54
- AcurÃ¡cia Direcional: **72.22%**

**Notebooks DisponÃ­veis**:
- `LSTM_BASE.ipynb` - Template base
- `LSTM_PETR4.ipynb` - Modelo otimizado para PETR4
- `LSTM_ITUB4.ipynb` - Modelo otimizado para ITUB4
- `LSTM_VALE3.ipynb` - Modelo otimizado para VALE3

---

### FASE 3: Infraestrutura Azure - â³ **PENDENTE**

#### 3.1 Cosmos DB

- [ ] Provisionar recurso Cosmos DB
- [ ] Configurar consistency level
- [ ] Criar container `model_versions`
- [ ] Criar container `training_metrics`
- [ ] Criar container `predictions`

#### 3.2 Storage Account

- [ ] Criar pasta `/hyperparameters` (JSONs de hiperparÃ¢metros por ticker)
- [ ] Criar pasta `/models` (modelos treinados versionados)
- [ ] Estruturar organizaÃ§Ã£o de arquivos

#### 3.3 Application Insights

- [x] Habilitado no Data-Service
- [ ] Habilitar no Stock-Service (quando criado)
- [ ] Configurar retention period
- [ ] Configurar alertas bÃ¡sicos (opcional)

---

### FASE 4: Stock-Service (Azure Function) - â³ **PENDENTE**

#### 4.1 Setup Inicial

- [ ] Criar Function App `tc-4-stock-service`
- [ ] Configurar variÃ¡veis de ambiente
- [ ] Habilitar Application Insights
- [ ] Implementar health check `/health`

#### 4.2 Endpoint `/train`

- [ ] Carregar hiperparÃ¢metros de `/hyperparameters/{ticker}.json`
- [ ] Carregar dados histÃ³ricos de `/history/{ticker}.parquet`
- [ ] Executar pipeline de treinamento
- [ ] Gerenciar versionamento (Cosmos DB)
- [ ] Salvar modelo em `/models/{ticker}_v{version}.pt`
- [ ] Salvar scaler em `/models/{ticker}_v{version}_scaler.pkl`
- [ ] Salvar mÃ©tricas em Cosmos DB

#### 4.3 Endpoint `/predict`

- [ ] Validar versÃ£o do modelo
- [ ] Implementar cache de prediÃ§Ãµes (Cosmos DB)
- [ ] Carregar Ãºltimos 90 dias para prediÃ§Ã£o
- [ ] Retornar prediÃ§Ã£o com flag `from_cache`

#### 4.4 Deploy

- [ ] Criar Dockerfile (se necessÃ¡rio)
- [ ] Deploy via Azure CLI ou VS Code Extension
- [ ] Testar endpoints individualmente
- [ ] Validar integraÃ§Ã£o com Storage e Cosmos

---

### FASE 5: API Management (APIM) - â³ **PENDENTE**

#### 5.1 Setup APIM

- [ ] Criar recurso API Management (Developer tier)
- [ ] Aguardar provisionamento
- [ ] Configurar domÃ­nio customizado (opcional)

#### 5.2 Importar APIs

- [ ] Importar Data-Service como API `/data`
- [ ] Importar Stock-Service como API `/stock`

#### 5.3 Configurar SeguranÃ§a

- [ ] Mudar `authLevel` para `ANONYMOUS` nas Functions
- [ ] Criar Subscription Keys (principal + secundÃ¡ria)
- [ ] Configurar polÃ­tica de validaÃ§Ã£o de header
- [ ] Testar autenticaÃ§Ã£o

#### 5.4 PolÃ­ticas e ConfiguraÃ§Ãµes

- [ ] Configurar CORS
- [ ] Configurar rate limiting (throttling)
- [ ] Configurar cache de respostas (opcional)
- [ ] Habilitar logging detalhado

#### 5.5 DocumentaÃ§Ã£o

- [ ] Gerar documentaÃ§Ã£o Swagger/OpenAPI automÃ¡tica
- [ ] Exportar especificaÃ§Ã£o OpenAPI
- [ ] Disponibilizar developer portal (opcional)

---

### FASE 6: Dashboards e Monitoramento - â³ **PENDENTE**

#### 6.1 Dashboard de Infraestrutura (Application Insights)

- [ ] Uptime (disponibilidade dos serviÃ§os)
- [ ] Tempo mÃ©dio de resposta por endpoint
- [ ] Taxa de sucesso (2xx vs 4xx/5xx)
- [ ] Throughput (requests/minuto)
- [ ] LatÃªncia P95/P99
- [ ] Erros e Exceptions

#### 6.2 Dashboard de MÃ©tricas de ML (Cosmos DB)

- [ ] Tabela de versÃµes com mÃ©tricas
- [ ] GrÃ¡fico de evoluÃ§Ã£o do MAE por versÃ£o
- [ ] ComparaÃ§Ã£o de mÃ©tricas entre versÃµes
- [ ] AcurÃ¡cia direcional por versÃ£o e ticker
- [ ] Total de prediÃ§Ãµes realizadas
- [ ] Ãšltima prediÃ§Ã£o por ticker

#### 6.3 Montagem dos Dashboards

- [ ] Criar dashboard no Portal Azure
- [ ] Organizar layout (infra + ML)
- [ ] Compartilhar dashboard

#### 6.4 Alertas

- [ ] Alerta se uptime < 95%
- [ ] Alerta se tempo mÃ©dio de resposta > 5s
- [ ] Alerta se taxa de erro > 5%
- [ ] Alerta se treinamento falhar

---

### FASE 7: Testes End-to-End - â³ **PENDENTE**

#### 7.1 Fluxo de Treinamento

- [ ] Chamar `/stock/train` via APIM
- [ ] Verificar modelo salvo
- [ ] Verificar registro em Cosmos DB
- [ ] Validar mÃ©tricas

#### 7.2 Fluxo de PrediÃ§Ã£o

- [ ] Chamar `/stock/predict` (primeira vez)
- [ ] Verificar cache funcionando
- [ ] Testar `forcePredict: true`

#### 7.3 ValidaÃ§Ã£o de AutenticaÃ§Ã£o

- [ ] Testar sem Subscription Key (401)
- [ ] Testar com chave invÃ¡lida (403)
- [ ] Testar com chave vÃ¡lida (200)
- [ ] Validar rate limiting (429)

#### 7.4 ValidaÃ§Ã£o de Monitoramento

- [ ] Verificar logs no Application Insights
- [ ] Verificar dashboards atualizando
- [ ] Testar health checks

---

### FASE 8: DocumentaÃ§Ã£o e Entrega - â³ **PENDENTE**

#### 8.1 DocumentaÃ§Ã£o TÃ©cnica

- [x] README.md principal (este arquivo)
- [ ] Diagrama de arquitetura visual
- [ ] DocumentaÃ§Ã£o de API (OpenAPI/Swagger)
- [ ] Exemplos de uso (curl/Postman)
- [ ] Troubleshooting comum

#### 8.2 VÃ­deo Demonstrativo

- [ ] Gravar screencast (6-8 minutos)
- [ ] Editar vÃ­deo
- [ ] Adicionar narraÃ§Ã£o
- [ ] Hospedar (YouTube/Vimeo)

#### 8.3 OrganizaÃ§Ã£o do RepositÃ³rio

- [x] Estrutura de pastas organizada
- [ ] Adicionar `.gitignore` completo
- [ ] Incluir exemplos de configuraÃ§Ã£o (sem secrets)
- [ ] Adicionar LICENSE

---

## ğŸ“¦ PrÃ©-requisitos

### Local Development

- Python 3.11+
- [uv](https://github.com/astral-sh/uv) (gerenciador de pacotes)
- Jupyter Lab (para notebooks)
- Azure CLI (para deploy)
- VS Code com extensÃ£o Azure Functions (opcional)

### Azure Resources

- Azure Subscription
- Storage Account (jÃ¡ configurado)
- Cosmos DB Account (pendente)
- Application Insights (jÃ¡ configurado no Data-Service)
- API Management (pendente)

---

## ğŸ“ Estrutura do Projeto

```
tech-challenge-04/
â”œâ”€â”€ data-service/              # Azure Function - Coleta de Dados
â”‚   â”œâ”€â”€ function_app.py        # Endpoints: fetch-history, fetch-day, health
â”‚   â”œâ”€â”€ host.json              # ConfiguraÃ§Ã£o do Function App
â”‚   â”œâ”€â”€ local.settings.json    # VariÃ¡veis de ambiente (local)
â”‚   â”œâ”€â”€ requirements.txt       # DependÃªncias Python
â”‚   â”œâ”€â”€ pyproject.toml         # ConfiguraÃ§Ã£o do projeto
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ config.py          # Gerenciamento de configuraÃ§Ãµes
â”‚       â”œâ”€â”€ storage.py         # Cliente Azure Storage
â”‚       â”œâ”€â”€ yfinance_client.py # Cliente yfinance
â”‚       â”œâ”€â”€ parquet_handler.py # ManipulaÃ§Ã£o de arquivos Parquet
â”‚       â””â”€â”€ feature_engineering.py  # 23 indicadores tÃ©cnicos
â”‚
â”œâ”€â”€ stock-service/             # Azure Function - ML Service [PENDENTE]
â”‚   â”œâ”€â”€ function_app.py        # Endpoints: train, predict, health
â”‚   â”œâ”€â”€ model.py               # Classe LSTM (PyTorch Lightning)
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ notebooks/                 # Desenvolvimento Local do Modelo
â”‚   â”œâ”€â”€ LSTM_BASE.ipynb        # Template base
â”‚   â”œâ”€â”€ LSTM_PETR4.ipynb       # Modelo otimizado PETR4
â”‚   â”œâ”€â”€ LSTM_ITUB4.ipynb       # Modelo otimizado ITUB4
â”‚   â”œâ”€â”€ LSTM_VALE3.ipynb       # Modelo otimizado VALE3
â”‚   â”œâ”€â”€ configs/               # HiperparÃ¢metros por ticker
â”‚   â”‚   â”œâ”€â”€ PETR4.json
â”‚   â”‚   â”œâ”€â”€ ITUB4.json
â”‚   â”‚   â””â”€â”€ VALE3.json
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ train/             # Dados de treino (.parquet)
â”‚   â”‚   â””â”€â”€ predict/           # Dados para prediÃ§Ã£o
â”‚   â”œâ”€â”€ models/                # Modelos salvos (.ckpt)
â”‚   â””â”€â”€ lightning_logs/        # Logs do TensorBoard
â”‚
â”œâ”€â”€ docs/                      # DocumentaÃ§Ã£o [PENDENTE]
â”‚   â”œâ”€â”€ architecture_diagram.png
â”‚   â”œâ”€â”€ openapi_spec.yaml
â”‚   â””â”€â”€ video_demo_link.md
â”‚
â”œâ”€â”€ dashboards/                # Dashboards Azure [PENDENTE]
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ README.md                  # Este arquivo
```

---

## ğŸš€ InstalaÃ§Ã£o e Setup

### 1. Clonar RepositÃ³rio

```bash
git clone <repository-url>
cd tech-challenge-04
```

### 2. Setup Data-Service (Local)

```bash
cd data-service

# Instalar dependÃªncias
uv sync
# ou
pip install -r requirements.txt

# Configurar variÃ¡veis de ambiente
cp local.settings.json.example local.settings.json
# Editar local.settings.json com suas credenciais Azure
```

**VariÃ¡veis de Ambiente NecessÃ¡rias**:
- `AzureWebJobsStorage` - Connection string do Storage Account
- `TICKERS` - Lista de tickers (ex: "PETR4,ITUB4,VALE3")
- `CONTAINER_NAME` - Nome do container no Storage

### 3. Setup Notebooks (Local)

```bash
cd notebooks

# Instalar dependÃªncias
uv sync

# Ativar ambiente virtual
source .venv/bin/activate

# Iniciar Jupyter
jupyter lab
```

### 4. Executar Data-Service Localmente

```bash
cd data-service
func start
```

**Endpoints Locais**:
- `http://localhost:7071/api/fetch-history`
- `http://localhost:7071/api/fetch-day`
- `http://localhost:7071/api/health`

### 5. Deploy para Azure

```bash
# Login no Azure
az login

# Deploy do Data-Service
cd data-service
func azure functionapp publish <function-app-name>
```

---

## ğŸ“Š Features Utilizadas (23 Indicadores)

| Categoria | Indicadores |
|-----------|-------------|
| **PreÃ§o** | Open, High, Low, Adj Close |
| **Volume** | Volume, relative_volume, volume_ratio_5 |
| **Momentum** | RSI (7, 14), Stochastic K, ROC |
| **TendÃªncia** | MA (3, 5, 9), distance_ma3, distance_ma9 |
| **Volatilidade** | volatility_5d, volatility_ratio, Bollinger Position |
| **MACD** | macd_histogram |
| **Outros** | gap, return_1d, return_3d |

---

## ğŸ“ˆ Resultados Obtidos

### PETR4 (Petrobras)

| MÃ©trica | Valor |
|---------|-------|
| **RÂ²** | 63.26% |
| **MAPE** | 1.40% |
| **MAE** | R$ 0.54 |
| **AcurÃ¡cia Direcional** | 72.22% |

### ITUB4 (ItaÃº Unibanco)

ğŸ”§ Em otimizaÃ§Ã£o...

### VALE3 (Vale)

ğŸ”§ Em otimizaÃ§Ã£o...

---

## ğŸ”§ Tecnologias Utilizadas

- **Python** 3.11+
- **PyTorch** 2.x
- **PyTorch Lightning** 2.x
- **Azure Functions** (Python)
- **Azure Storage Account** (Blob Storage)
- **Azure Cosmos DB** (pendente)
- **Azure API Management** (pendente)
- **Application Insights**
- **yfinance** (coleta de dados)
- **pandas** / **numpy** (manipulaÃ§Ã£o de dados)
- **scikit-learn** (normalizaÃ§Ã£o, mÃ©tricas)

---

## ğŸ“š DocumentaÃ§Ã£o Detalhada

### Data-Service

O Data-Service Ã© responsÃ¡vel por coletar dados histÃ³ricos e diÃ¡rios das aÃ§Ãµes, aplicar feature engineering e salvar em formato Parquet no Azure Storage.

**Endpoints**:

1. **GET /api/fetch-history**
   - Busca histÃ³rico completo configurado
   - Aplica feature engineering (modo treino)
   - Salva em `/history/{ticker}.parquet`

2. **GET /api/fetch-day**
   - Busca Ãºltimos 90 dias
   - Aplica feature engineering (modo prediÃ§Ã£o)
   - Salva em `/YYYY/MM/DD/{ticker}.parquet`

3. **GET /api/health**
   - Health check do serviÃ§o
   - Retorna status e timestamp

### Modelo LSTM

O modelo LSTM foi desenvolvido localmente usando PyTorch Lightning. Cada ticker possui sua prÃ³pria configuraÃ§Ã£o de hiperparÃ¢metros em `notebooks/configs/{TICKER}.json`.

**Arquitetura**:
- 3 camadas LSTM empilhadas
- Dropout para regularizaÃ§Ã£o
- NormalizaÃ§Ã£o MinMax separada para features e target
- Early stopping e learning rate scheduler

**MÃ©tricas Calculadas**:
- MAE (Mean Absolute Error)
- RMSE (Root Mean Squared Error)
- MAPE (Mean Absolute Percentage Error)
- RÂ² (Coeficiente de DeterminaÃ§Ã£o)
- AcurÃ¡cia Direcional

---

## ğŸ—ºï¸ Roadmap

### PrÃ³ximos Passos Imediatos

1. **FASE 3**: Provisionar Cosmos DB e estruturar Storage Account
2. **FASE 4**: Desenvolver e deployar Stock-Service
3. **FASE 5**: Configurar API Management
4. **FASE 6**: Criar dashboards de monitoramento
5. **FASE 7**: Executar testes end-to-end
6. **FASE 8**: Finalizar documentaÃ§Ã£o e vÃ­deo

### Melhorias Futuras

- [ ] Implementar retreinamento automÃ¡tico periÃ³dico
- [ ] Adicionar mais indicadores tÃ©cnicos
- [ ] Experimentar outras arquiteturas (Transformer, GRU)
- [ ] Implementar ensemble de modelos
- [ ] Adicionar prediÃ§Ã£o de mÃºltiplos dias (D+2, D+3, etc.)
- [ ] Dashboard web interativo (Streamlit/React)
- [ ] NotificaÃ§Ãµes via email/Teams quando prediÃ§Ãµes excedem threshold

---

## ğŸ¤ Contribuindo

Este Ã© um projeto acadÃªmico desenvolvido para o **Tech Challenge 04** da FIAP.

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© de uso acadÃªmico.

---

## ğŸ“ Contatos e Recursos

- **RepositÃ³rio Git**: [(https://github.com/rebertmatheus/tech-challenge-04)]
- **Azure Portal**: [adicionar link do resource group]
- **Dashboard de Monitoramento**: [adicionar link quando criado]
- **DocumentaÃ§Ã£o API**: [adicionar link do APIM portal]

---

**Documento atualizado em**: Janeiro de 2025  
**VersÃ£o**: 1.0  
**Autor**: Equipe Tech Challenge 04

